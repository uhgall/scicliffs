
Come up with a good, catchy headline for the article below that is accurate and informative,
but also designed to get people to click on it. The headline should be 10 words or less.

---

 Here is a blog post on the arXiv paper "Reasoning with Language Model is Planning with World Model" in the style of a top science blog on Substack for a first principles audience with a good general science background:

# LLMs Gain World Model Capabilities for Strategic Reasoning 

Researchers at UC San Diego and University of Florida have developed a new framework that allows large language models (LLMs) to perform complex reasoning through strategic planning - much like humans do. 

## The Limitations of Current LLM Reasoning

While LLMs have shown impressive reasoning abilities on tasks like math word problems, they struggle with tasks requiring multi-step plans or long-term thinking. This is because LLMs lack two key capabilities:

1. **Internal world model** - Humans have mental representations of the environment that let us simulate actions and predict outcomes. LLMs don't have this.

2. **Strategic planning** - Humans plan deliberately by exploring action sequences, anticipating outcomes, and refining plans. LLMs can't balance exploration versus exploitation to efficiently search the vast solution space.

## Repurposing the LLM as a World Model 

The researchers overcome this by building a "world model" using the LLM itself. They define the "state" as describing the problem situation (like block positions), and "actions" as steps changing the state (like moving a block). 

They then repurpose the LLM to serve two roles - as a "reasoning agent" generating actions, and as the "world model" predicting how states change. This allows simulating the reasoning process without external interactions.

## Planning with Monte Carlo Tree Search

With states and a world model in place, they apply principled planning algorithms. Specifically, they use Monte Carlo Tree Search (MCTS) to build a "tree" of potential reasoning steps. 

At each step, the LLM strategically expands promising branches of the tree while the world model looks ahead to anticipate rewards. Estimated future rewards are backpropagated to guide improving the reasoning. This balancing of exploration and exploitation efficiently searches the solution space.

## Results on Diverse Reasoning Tasks

The framework, called "Reasoning via Planning" (RAP), shows significant gains over current approaches on tasks like block rearranging plans, math word problems, and logical reasoning. 

For example, on 6-step block rearrangement plans solvable by humans, RAP succeeds 42% of the time within 20 tree search iterations, while previous methods completely fail. RAP scales to problems too complex for humans to solve consciously.

By imbuing LLMs with world modeling and planning skills, RAP may fundamentally advance how we approach reasoning with AI - moving it towards human-like strategic thinking. The framework has potential as a general solution to diverse complex reasoning problems.