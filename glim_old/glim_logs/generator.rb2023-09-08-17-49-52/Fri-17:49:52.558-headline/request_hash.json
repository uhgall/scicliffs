# request_hash generated by GlimRequest with AnthropicRequestDetails
{
  "max_tokens_to_sample": 2000,
  "model": "claude-2",
  "prompt": "\n\nCome up with a good, catchy headline for the article below that is accurate and informative,\nbut also designed to get people to click on it. The headline should be 10 words or less.\n\n---\n Here is a draft blog post about the paper:\n\n# New AI Reasoning Method Mimics Human Planning\n\nResearchers at UC San Diego, University of Florida, and Zhiting Hu have developed a new method that enables large language models (LLMs) like GPT-3 to reason more like humans through planning. \n\nIn a paper published on ArXiv, the researchers present Reasoning via Planning (RAP), a framework that gives LLMs a sense of an internal \"world model\" and the ability to do planning by simulating future states - just like humans contemplate potential outcomes in their minds.\n\n## The Limitations of LLMs\n\nLLMs like GPT-3 have shown impressive reasoning capabilities. When prompted to break down a complex question into a chain of reasoning steps, they can provide coherent explanations. \n\nHowever, LLMs still struggle with tasks that require looking ahead and deliberating over future outcomes. For example, when asked to rearrange blocks into a target configuration, GPT-3 only succeeds 1% of the time, compared to 78% for humans. \n\nThe researchers identify several key deficiencies preventing LLMs from more human-like reasoning:\n\n- **Lack of internal world model:** LLMs cannot predict how the world or environment will change in response to actions. Humans leverage such a mental model to look ahead.\n\n- **No reward mechanism:** LLMs have no way to assess if a reasoning step is good or bad. Humans get internal feedback on potential choices. \n\n- **Inability to balance exploration vs exploitation:** LLMs cannot efficiently explore the vast space of possible reasoning paths like humans.\n\n## Introducing Planning into LLMs\n\nTo address these gaps, the researchers developed RAP to bring human-like planning into LLM reasoning. RAP has two key components:\n\n- **World Model:** The LLM is repurposed to simulate how the world state changes in response to actions. This is like a human mentally contemplating outcomes.\n\n- **Planning Algorithm:** RAP incorporates Monte Carlo Tree Search, which efficiently explores reasoning trees to find high-reward paths. This balances exploration vs exploitation. \n\nDuring reasoning, the LLM incrementally builds a tree of potential reasoning chains under guidance from the world model and rewards. The planning algorithm steers the LLM towards high-quality reasoning steps.\n\nThis allows the LLM to deliberate over future states and iteratively improve its reasoning - just like human planning.\n\n## Better Performance on Diverse Reasoning Tasks\n\nThe researchers tested RAP on a variety of challenging reasoning tasks:\n\n- **Block Rearranging:** RAP achieved 64% success vs nearly 0% for standard CoT prompting. It even exceeded GPT-4.\n\n- **Math Word Problems:** RAP improved accuracy to 48.6% from 29.4% for CoT on grade-school math questions.\n\n- **Logical Reasoning:** RAP boosted proof accuracy to 78.8% from 64.8% compared to CoT on a formal logic dataset. \n\nThe consistent significant gains across diverse domains clearly demonstrate RAP's ability to enhance LLM reasoning.\n\n## A More General and Human-like Approach\n\nRAP provides a general framework for formulating reasoning tasks in terms of states, actions and rewards. This flexibility allows it to handle a wide variety of problems, bringing LLMs closer to human-level strategic planning.\n\nBy looking ahead using a world model and deliberately exploring reasoning chains, RAP overcomes key deficiencies of LLMs. The researchers believe RAP defines a promising new path towards more sophisticated reasoning in artificial intelligence.\n\nOverall, RAP's innovative melding of planning into LLM reasoning takes a meaningful step towards achieving the complex cognitive abilities and foresight that comes naturally to humans. The future looks bright for more human-like thinking in AI!\n---\n\nRespond only with the headline, nothing else.\n"
}