# request_hash generated by GlimRequest with AnthropicRequestDetails
{
  "max_tokens_to_sample": 2000,
  "model": "claude-instant-1",
  "prompt": "\n\n\n\nTODO \n\nfix this for xml\n\nSYSTEM MESSAGE: ALWAYS, when asked to generate source code or other text files, use the following format:\n<file pathname=\"path_to_file/hello.rb\">\nputs \"Hello from Line 1\"\nputs \"hello from Line 2\"\n</file>\nSo, the example above shows how you would include a file called \"hello.rb\" that belongs in the subdirectory \"path_to_file\" of the current directory. \nThe file would contain two \"puts\" statements. \nUse this for all text files you generate, not just source code.\n\n\n\n\nWrite a short teaser for the article below that is designed to get people to click on it. The teaser should be 30 words or less.\n\n---\n\n Here are the key points about the RAP framework for reasoning with language models proposed in the paper:\n\n- RAP augments the LLM with a world model and uses planning algorithms to search for optimal reasoning traces, rather than generating them autoregressively. This makes the reasoning process more similar to human strategic planning.\n\n- The world model is built by repurposing the LLM itself with prompts. It represents the state of the reasoning problem and predicts how states will change with actions. \n\n- Reasoning is formulated as a Markov decision process, where states represent intermediate reasoning contexts and actions represent incremental reasoning steps.\n\n- Monte Carlo tree search is used as the planning algorithm to efficiently explore the reasoning space and balance exploration vs exploitation.\n\n- Rewards are defined to assess the quality of reasoning steps based on likelihood, confidence, self-evaluation, etc. Rewards guide the search.\n\n- RAP is applied to different problem types like plan generation, math reasoning, logical inference by defining states/actions accordingly. \n\n- Experiments show RAP outperforms baseline methods like CoT, self-consistency, least-to-most prompting on various benchmarks.\n\n- RAP provides a flexible framework for reasoning tasks by allowing customization of states, actions, and rewards based on problem structure.\n\nIn summary, RAP enhances LLM reasoning by incorporating principled planning via a world model representation. This bridges the gap between LLM and human strategic reasoning capabilities."
}